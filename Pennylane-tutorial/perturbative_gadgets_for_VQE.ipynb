{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturbative Gadgets for Variational Quantum Algorithms  \n",
    "==========================================\n",
    "\n",
    "*Author: Simon Cichy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will explore the application of perturbative gadgets in \n",
    "variational quantum algorithms to outgo the issue of cost function dependent\n",
    "barren plateaus, as proposed in Ref.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some context\n",
    "---------------------------\n",
    "\n",
    "If you are not familiar yet with the concept of barren plateaus, I recomend you\n",
    "first check out these other tutorials: \n",
    "- https://pennylane.ai/qml/demos/tutorial_barren_plateaus.html\n",
    "- https://pennylane.ai/qml/demos/tutorial_local_cost_functions.html  \n",
    "\n",
    "As presented in the second, barren plateaus are more severe when using global\n",
    "cost functions compared to local ones. \n",
    "We want to explore this topic further and learn about one possible mitigation\n",
    "strategy.  \n",
    "Thinking about VQE applications, let us consider cost functions that are \n",
    "expectation values of Hamiltonians like\n",
    "$$ C = \\operatorname{Tr} \\left[ H V(\\theta) |00\\ldots 0\\rangle \\langle 00\\ldots 0| V(\\theta)^\\dagger\\right]. $$\n",
    "As you will see later, that is easy to do using the\n",
    "<a href=\"https://pennylane.readthedocs.io/en/stable/code/api/pennylane.ExpvalCost.html\">qml.ExpvalCost</a> \n",
    "class.  \n",
    "In some cases, it is easy to find a local cost function to substitute a global\n",
    "one, which still has the same ground state. \n",
    "For instance, one can verify that the local cost function built from \n",
    "$$ H_L = \\mathbb{I} - \\frac{1}{n} \\sum_j |0\\rangle \\langle 0|_j $$\n",
    "has the same ground state as the global one\n",
    "$$ H_G = \\mathbb{I} - |00\\ldots 0\\rangle \\langle 00\\ldots 0|  $$\n",
    "and that is \n",
    "$$ |\\psi (\\theta_{min}) \\rangle =  |00\\ldots 0\\rangle. $$\n",
    "However, it is not always so simple. \n",
    "What if we want to find the minimum eigenenergy of \n",
    "$ H = X \\otimes X \\otimes Y \\otimes Z + Z \\otimes Y \\otimes X \\otimes X $ ?  \n",
    "It is not always (or rather almost never) trivial to construct a local cost \n",
    "function which has the same minimum as some other cost function of interest,\n",
    "global however. \n",
    "That is where perturbative gadgets come into play, and we will see how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definitions\n",
    "---------------\n",
    "Perturbative gadgets are a common tool in adiabatic quantum computing. \n",
    "Their goal is to find a Hamiltonian with local interactions which mimics\n",
    "some other Hamiltonian with more complex couplings. \n",
    "The later is the one they would ideally want to implement for their\n",
    "computation, that's why it is called the computational Hamiltonian, but can not\n",
    "since it is hard to implement more than few-body interactions in hardware.\n",
    "This is done by increasing the dimension of the Hilbert space (i.e. the number \n",
    "of qubits) and \"encoding\" the computational Hamiltonian in the low-energy \n",
    "subspace of a so-called gadget Hamiltonian.\n",
    "Let us now construct such a gadget Hamiltonian taylored for VQE applications.  \n",
    "\n",
    "First, we start from a target Hamiltonian which is a linear combination of \n",
    "Pauli words, acting on $k$ qubits\n",
    "$$ H^\\text{targ} = \\sum_i c_i h_i $$\n",
    "with $ h_i = \\sigma_{i,1} \\otimes \\sigma_{i,2} \\otimes \\ldots \\otimes \\sigma_{i,k} $\n",
    "and $ \\sigma_{i,j} \\in \\{ X, Y, Z \\}$, $ c_i \\in \\mathbb{R}$.  \n",
    "Now we construct the gadget Hamiltonian.\n",
    "For each term $h_i$, we will need $k$ additional qubits qubits which we call \n",
    "auxiliary qubits, and add two terms to the Hamiltonian: \n",
    "an \"unperturbed\" part $h^\\text{aux}_s$ and a perturbation $\\lambda V_s$. \n",
    "The unperturbed part penalizes each of the newly added qubits for not being in \n",
    "the $|0\\rangle$ state\n",
    "$$ h^\\text{aux}_i = \\sum_{j=1}^k |1\\rangle \\langle 1|_{i,j}$$\n",
    "while the perturbation part implements one of the operators in the Pauli word\n",
    "$\\sigma_{i,j}$ on the corresponding qubit of the computational register and a \n",
    "pair of Pauli $X$ gates on two of the auxiliary qubits\n",
    "$$ V_i = \\sum_{j=1}^k c_{i,j} \\sigma_{i,j} \\otimes X_{i,j} \\otimes X_{i,(j+1) \\mathrm{mod }k}. $$\n",
    "In the end, \n",
    "$$ H^\\text{gad} = \\sum_{i} \\left( h^\\text{aux}_i + \\lambda V_i \\right) $$  \n",
    "TODO: add picture of registers  \n",
    "TODO: finish explanation of gadgets  \n",
    "TODO: add figure about gadget analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the gadget Hamiltonian\n",
    "----------------------------------\n",
    "Now that we have layed the definitions, let us get to the code and have a look \n",
    "at one of these constructions to get used to them. \n",
    "First we will have to import a few packages  \n",
    "TODO: check with Pennylane team how to do it with the PerturbativeGadget class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('src')\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from barren_gadgets import PerturbativeGadgets\n",
    "from layered_ansatz import build_ansatz, generate_random_gate_sequence, get_parameter_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take the example given above \n",
    "$$ H = X \\otimes X \\otimes Y \\otimes Z + Z \\otimes Y \\otimes X \\otimes X. $$\n",
    "First we construct our target Hamiltonian in Pennylane.\n",
    "For this, we use the \n",
    "<a href=\"https://pennylane.readthedocs.io/en/stable/code/api/pennylane.Hamiltonian.html\">qml.Hamiltonian</a> \n",
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = qml.operation.Tensor(qml.PauliX(0), qml.PauliX(1), qml.PauliY(2), qml.PauliZ(3))\n",
    "term2 = qml.operation.Tensor(qml.PauliZ(0), qml.PauliY(1), qml.PauliX(2), qml.PauliX(3))\n",
    "Hcomp = qml.Hamiltonian([1,1], [term1, term2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check that we constructed indeed what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1) [X0 X1 Y2 Z3]\n",
      "+ (1) [Z0 Y1 X2 X3]\n"
     ]
    }
   ],
   "source": [
    "print(Hcomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indeed have a Hamiltonian composed of two terms, with the Pauli words\n",
    "which we wanted. \n",
    "Next, we can construct the corresponding gadget Hamiltonian. \n",
    "Using the class NewPerturbativeGadgets (rename VQEGadgets?), we can automatedly \n",
    "generate the gadget Hamiltonian from the computational Hamiltonian.\n",
    "The object gadgetizer will contain all the information about the settings of \n",
    "the gadgetization procedure (there are quite a few knobs one can tweak on, \n",
    "but we'll skip that for now). \n",
    "Then, the method gadgetize takes a qml.Hamiltonian object and generates the\n",
    "corresponding gadget Hamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (-0.5) [Z4]\n",
      "+ (-0.5) [Z5]\n",
      "+ (-0.5) [Z6]\n",
      "+ (-0.5) [Z7]\n",
      "+ (-0.5) [Z8]\n",
      "+ (-0.5) [Z9]\n",
      "+ (-0.5) [Z10]\n",
      "+ (-0.5) [Z11]\n",
      "+ (0.5) [I4]\n",
      "+ (0.5) [I5]\n",
      "+ (0.5) [I6]\n",
      "+ (0.5) [I7]\n",
      "+ (0.5) [I8]\n",
      "+ (0.5) [I9]\n",
      "+ (0.5) [I10]\n",
      "+ (0.5) [I11]\n",
      "+ (-0.03125) [X4 X5 X0]\n",
      "+ (-0.03125) [X8 X9 Z0]\n",
      "+ (0.03125) [X5 X6 X1]\n",
      "+ (0.03125) [X6 X7 Y2]\n",
      "+ (0.03125) [X7 X4 Z3]\n",
      "+ (0.03125) [X9 X10 Y1]\n",
      "+ (0.03125) [X10 X11 X2]\n",
      "+ (0.03125) [X11 X8 X3]\n"
     ]
    }
   ],
   "source": [
    "gadgetizer = PerturbativeGadgets()\n",
    "Hgad = gadgetizer.gadgetize(Hcomp)\n",
    "print(Hgad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's see what we got.  \n",
    "We started with 4 computational qubits (labelled 0 to 3) and two 4-body terms.\n",
    "Thus we get 4 additional qubits twice (4 to 11).\n",
    "The first 16 elements of our Hamiltonian correspond to the unperturbed part.\n",
    "The last 8 are the perturbation. They are a little scambled, but one can \n",
    "recognize the 8 Paulis from the computational Hamiltonian on the qubits 0 to 3\n",
    "and the cyclic pairwise $X$ structure on the auxiliaries. \n",
    "Indeed, there are $(X_4X_5, X_5X_6, X_6X_7, X_7X_4)$ and \n",
    "$(X_8X_9, X_9X_{10}, X_{10}X_{11}, X_{11}X_8)$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with the gadget Hamiltonian\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a little intuition on how the gadget Hamiltonian construction\n",
    "works, we will use it to train. \n",
    "Classical simulation of qubit systems is expensive, so we will simplify further\n",
    "to a computational Hamiltonian with a single term, and show that using the \n",
    "gadget Hamiltonian for training allows us to minimize the target Hamiltonian.  \n",
    "So, let us construct the two Hamiltonians of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "term1 = qml.operation.Tensor(qml.PauliX(0), qml.PauliY(1), qml.PauliZ(2), qml.PauliZ(3))\n",
    "Hcomp = qml.Hamiltonian([1], [term1])\n",
    "perturbation_factor = 10\n",
    "gadgetizer = PerturbativeGadgets(perturbation_factor)\n",
    "Hgad = gadgetizer.gadgetize(Hcomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to set up our variational quantum algorithms. \n",
    "That is we choose a circuit ansatz with randomly initialized weights, \n",
    "the training cost function, the optimizer with its step size, and the number of \n",
    "optimization steps and the device to run the circuit on.  \n",
    "As ansatz, we will use a variation of the \n",
    "<a href=\"https://pennylane.readthedocs.io/en/latest/code/api/pennylane.SimplifiedTwoDesign.html#pennylane.SimplifiedTwoDesign\">qml.SimplifiedTwoDesign</a>, which was proposed in previous \n",
    "works on cost function dependent barren plateaus [2].  \n",
    "Here is what it looks like for a small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(0.79)─╭C──RZ(2.44)──────────────╭C──RX(0.10)──────────────╭C──RZ(1.78)──────────────┤  <Z>\n",
      "1: ──RY(0.79)─╰Z──RZ(1.47)─╭C──RY(0.49)─╰Z──RZ(1.01)─╭C──RX(0.26)─╰Z──RX(0.43)─╭C──RY(2.67)─┤     \n",
      "2: ──RY(0.79)─╭C──RY(2.39)─╰Z──RX(1.24)─╭C──RX(2.74)─╰Z──RY(2.43)─╭C──RX(1.70)─╰Z──RY(2.27)─┤     \n",
      "3: ──RY(0.79)─╰Z──RX(0.83)─╭C──RZ(2.81)─╰Z──RZ(0.36)─╭C──RY(2.48)─╰Z──RX(0.19)─╭C──RZ(0.66)─┤     \n",
      "4: ──RY(0.79)──────────────╰Z──RX(1.39)──────────────╰Z──RZ(1.24)──────────────╰Z──RZ(2.63)─┤     \n"
     ]
    }
   ],
   "source": [
    "shapes = get_parameter_shape(n_layers=3, n_wires=5)\n",
    "init_weights = [np.pi/4] * shapes[0][0]\n",
    "weights = np.random.uniform(0, np.pi, size=shapes[1])\n",
    "@qml.qnode(qml.device(\"default.qubit\", wires=range(5)))\n",
    "def display_circuit(weights):\n",
    "    build_ansatz(initial_layer_weights=init_weights, weights=weights, wires=range(5))\n",
    "    return qml.expval(qml.PauliZ(wires=0))\n",
    "print(qml.draw(display_circuit)(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the circuit for our actual experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of qubits: computational + auxiliary\n",
    "num_qubits = 4 + 2 * 4\n",
    "\n",
    "# Other parameters of the ansatz: weights and gate sequence\n",
    "shapes = get_parameter_shape(n_layers=num_qubits, n_wires=num_qubits)\n",
    "init_weights = [np.pi/4] * shapes[0][0]\n",
    "weights = np.random.uniform(0, np.pi, size=shapes[1])\n",
    "random_gate_sequence = generate_random_gate_sequence(qml.math.shape(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the classical optimization, we will use the standard gradient descent\n",
    "algorithm, and perform 500 iterations. For the quantum part, we will simulate\n",
    "our circuit using the default.qubit simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
    "max_iter = 500\n",
    "dev = qml.device(\"default.qubit\", wires=range(num_qubits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use two cost functions. \n",
    "For each we create a QNode.\n",
    "The first, the training cost, is the loss function of the optimization, \n",
    "that's the one the gradient descent will actually try to minimize. \n",
    "For the training, we use the gadget Hamiltonian.\n",
    "Then we also define a monitoring cost, based on the target Hamiltonian.\n",
    "We will evaluate it's value at each iteration for monitoring purposes, but it \n",
    "will not be used in the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def training_cost(weights):\n",
    "    build_ansatz(initial_layer_weights=init_weights, \n",
    "                 weights=weights, wires=range(num_qubits), \n",
    "                 gate_sequence=random_gate_sequence)\n",
    "    return qml.expval(Hgad)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def monitoring_cost(weights):\n",
    "    build_ansatz(initial_layer_weights=init_weights, \n",
    "                 weights=weights, wires=range(num_qubits), \n",
    "                 gate_sequence=random_gate_sequence)\n",
    "    return qml.expval(Hcomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that if we reach the global minimum for the gadget Hamiltonian, we\n",
    "should also be close to the global minimum of the target Hamiltonian, which is\n",
    "what we are ultimately interested in.\n",
    "To be able to look how it went and maybe plot it, we will save the costs values\n",
    "at each iteration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_lists = {}\n",
    "costs_lists['training'] = [training_cost(weights)]\n",
    "costs_lists['monitoring'] = [monitoring_cost(weights)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is set up, let's run the optimization and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration =     0 of   500 | Training cost =   2.03592163 | Monitoring cost =  -0.01295161 | \n",
      "Iteration =     1 of   500 | Training cost =   1.96212953 | Monitoring cost =  -0.01119763 | \n",
      "Iteration =     2 of   500 | Training cost =   1.88811934 | Monitoring cost =  -0.00856274 | \n",
      "Iteration =     3 of   500 | Training cost =   1.81448559 | Monitoring cost =  -0.00493300 | \n",
      "Iteration =     4 of   500 | Training cost =   1.74177769 | Monitoring cost =  -0.00030220 | \n",
      "Iteration =     5 of   500 | Training cost =   1.67045812 | Monitoring cost =   0.00523451 | \n",
      "Iteration =     6 of   500 | Training cost =   1.60088001 | Monitoring cost =   0.01150172 | \n",
      "Iteration =     7 of   500 | Training cost =   1.53328472 | Monitoring cost =   0.01827274 | \n",
      "Iteration =     8 of   500 | Training cost =   1.46781431 | Monitoring cost =   0.02529903 | \n",
      "Iteration =     9 of   500 | Training cost =   1.40453106 | Monitoring cost =   0.03233495 | \n",
      "Iteration =    10 of   500 | Training cost =   1.34343796 | Monitoring cost =   0.03915525 | \n",
      "Iteration =    11 of   500 | Training cost =   1.28449682 | Monitoring cost =   0.04556549 | \n",
      "Iteration =    12 of   500 | Training cost =   1.22764325 | Monitoring cost =   0.05140650 | \n",
      "Iteration =    13 of   500 | Training cost =   1.17279903 | Monitoring cost =   0.05655469 | \n",
      "Iteration =    14 of   500 | Training cost =   1.11988217 | Monitoring cost =   0.06091988 | \n",
      "Iteration =    15 of   500 | Training cost =   1.06881474 | Monitoring cost =   0.06444200 | \n",
      "Iteration =    16 of   500 | Training cost =   1.01952797 | Monitoring cost =   0.06708736 | \n",
      "Iteration =    17 of   500 | Training cost =   0.97196463 | Monitoring cost =   0.06884497 | \n",
      "Iteration =    18 of   500 | Training cost =   0.92607872 | Monitoring cost =   0.06972312 | \n",
      "Iteration =    19 of   500 | Training cost =   0.88183337 | Monitoring cost =   0.06974611 | \n",
      "Iteration =    20 of   500 | Training cost =   0.83919784 | Monitoring cost =   0.06895125 | \n",
      "Iteration =    21 of   500 | Training cost =   0.79814453 | Monitoring cost =   0.06738595 | \n",
      "Iteration =    22 of   500 | Training cost =   0.75864662 | Monitoring cost =   0.06510516 | \n",
      "Iteration =    23 of   500 | Training cost =   0.72067664 | Monitoring cost =   0.06216894 | \n",
      "Iteration =    24 of   500 | Training cost =   0.68420600 | Monitoring cost =   0.05864050 | \n",
      "Iteration =    25 of   500 | Training cost =   0.64920503 | Monitoring cost =   0.05458441 | \n",
      "Iteration =    26 of   500 | Training cost =   0.61564346 | Monitoring cost =   0.05006533 | \n",
      "Iteration =    27 of   500 | Training cost =   0.58349080 | Monitoring cost =   0.04514683 | \n",
      "Iteration =    28 of   500 | Training cost =   0.55271655 | Monitoring cost =   0.03989056 | \n",
      "Iteration =    29 of   500 | Training cost =   0.52329020 | Monitoring cost =   0.03435557 | \n",
      "Iteration =    30 of   500 | Training cost =   0.49518083 | Monitoring cost =   0.02859776 | \n",
      "Iteration =    31 of   500 | Training cost =   0.46835665 | Monitoring cost =   0.02266938 | \n",
      "Iteration =    32 of   500 | Training cost =   0.44278439 | Monitoring cost =   0.01661867 | \n",
      "Iteration =    33 of   500 | Training cost =   0.41842879 | Monitoring cost =   0.01048950 | \n",
      "Iteration =    34 of   500 | Training cost =   0.39525220 | Monitoring cost =   0.00432120 | \n",
      "Iteration =    35 of   500 | Training cost =   0.37321435 | Monitoring cost =  -0.00185169 | \n",
      "Iteration =    36 of   500 | Training cost =   0.35227237 | Monitoring cost =  -0.00799938 | \n",
      "Iteration =    37 of   500 | Training cost =   0.33238099 | Monitoring cost =  -0.01409686 | \n",
      "Iteration =    38 of   500 | Training cost =   0.31349294 | Monitoring cost =  -0.02012370 | \n",
      "Iteration =    39 of   500 | Training cost =   0.29555945 | Monitoring cost =  -0.02606379 | \n",
      "Iteration =    40 of   500 | Training cost =   0.27853079 | Monitoring cost =  -0.03190508 | \n",
      "Iteration =    41 of   500 | Training cost =   0.26235695 | Monitoring cost =  -0.03763909 | \n",
      "Iteration =    42 of   500 | Training cost =   0.24698816 | Monitoring cost =  -0.04326057 | \n",
      "Iteration =    43 of   500 | Training cost =   0.23237549 | Monitoring cost =  -0.04876698 | \n",
      "Iteration =    44 of   500 | Training cost =   0.21847129 | Monitoring cost =  -0.05415807 | \n",
      "Iteration =    45 of   500 | Training cost =   0.20522959 | Monitoring cost =  -0.05943546 | \n",
      "Iteration =    46 of   500 | Training cost =   0.19260644 | Monitoring cost =  -0.06460221 | \n",
      "Iteration =    47 of   500 | Training cost =   0.18056005 | Monitoring cost =  -0.06966244 | \n",
      "Iteration =    48 of   500 | Training cost =   0.16905101 | Monitoring cost =  -0.07462105 | \n",
      "Iteration =    49 of   500 | Training cost =   0.15804232 | Monitoring cost =  -0.07948339 | \n",
      "Iteration =    50 of   500 | Training cost =   0.14749940 | Monitoring cost =  -0.08425503 | \n",
      "Iteration =    51 of   500 | Training cost =   0.13739007 | Monitoring cost =  -0.08894159 | \n",
      "Iteration =    52 of   500 | Training cost =   0.12768447 | Monitoring cost =  -0.09354855 | \n",
      "Iteration =    53 of   500 | Training cost =   0.11835495 | Monitoring cost =  -0.09808115 | \n",
      "Iteration =    54 of   500 | Training cost =   0.10937598 | Monitoring cost =  -0.10254427 | \n",
      "Iteration =    55 of   500 | Training cost =   0.10072402 | Monitoring cost =  -0.10694238 | \n",
      "Iteration =    56 of   500 | Training cost =   0.09237737 | Monitoring cost =  -0.11127951 | \n",
      "Iteration =    57 of   500 | Training cost =   0.08431605 | Monitoring cost =  -0.11555919 | \n",
      "Iteration =    58 of   500 | Training cost =   0.07652167 | Monitoring cost =  -0.11978448 | \n",
      "Iteration =    59 of   500 | Training cost =   0.06897731 | Monitoring cost =  -0.12395794 | \n",
      "Iteration =    60 of   500 | Training cost =   0.06166742 | Monitoring cost =  -0.12808167 | \n",
      "Iteration =    61 of   500 | Training cost =   0.05457765 | Monitoring cost =  -0.13215733 | \n",
      "Iteration =    62 of   500 | Training cost =   0.04769481 | Monitoring cost =  -0.13618614 | \n",
      "Iteration =    63 of   500 | Training cost =   0.04100676 | Monitoring cost =  -0.14016896 | \n",
      "Iteration =    64 of   500 | Training cost =   0.03450230 | Monitoring cost =  -0.14410629 | \n",
      "Iteration =    65 of   500 | Training cost =   0.02817110 | Monitoring cost =  -0.14799832 | \n",
      "Iteration =    66 of   500 | Training cost =   0.02200363 | Monitoring cost =  -0.15184497 | \n",
      "Iteration =    67 of   500 | Training cost =   0.01599110 | Monitoring cost =  -0.15564594 | \n",
      "Iteration =    68 of   500 | Training cost =   0.01012537 | Monitoring cost =  -0.15940072 | \n",
      "Iteration =    69 of   500 | Training cost =   0.00439893 | Monitoring cost =  -0.16310865 | \n",
      "Iteration =    70 of   500 | Training cost =  -0.00119519 | Monitoring cost =  -0.16676896 | \n",
      "Iteration =    71 of   500 | Training cost =  -0.00666346 | Monitoring cost =  -0.17038077 | \n",
      "Iteration =    72 of   500 | Training cost =  -0.01201187 | Monitoring cost =  -0.17394316 | \n",
      "Iteration =    73 of   500 | Training cost =  -0.01724599 | Monitoring cost =  -0.17745518 | \n",
      "Iteration =    74 of   500 | Training cost =  -0.02237101 | Monitoring cost =  -0.18091586 | \n",
      "Iteration =    75 of   500 | Training cost =  -0.02739177 | Monitoring cost =  -0.18432427 | \n",
      "Iteration =    76 of   500 | Training cost =  -0.03231281 | Monitoring cost =  -0.18767950 | \n",
      "Iteration =    77 of   500 | Training cost =  -0.03713833 | Monitoring cost =  -0.19098071 | \n",
      "Iteration =    78 of   500 | Training cost =  -0.04187233 | Monitoring cost =  -0.19422712 | \n",
      "Iteration =    79 of   500 | Training cost =  -0.04651852 | Monitoring cost =  -0.19741804 | \n",
      "Iteration =    80 of   500 | Training cost =  -0.05108041 | Monitoring cost =  -0.20055287 | \n",
      "Iteration =    81 of   500 | Training cost =  -0.05556133 | Monitoring cost =  -0.20363111 | \n",
      "Iteration =    82 of   500 | Training cost =  -0.05996440 | Monitoring cost =  -0.20665237 | \n",
      "Iteration =    83 of   500 | Training cost =  -0.06429259 | Monitoring cost =  -0.20961637 | \n",
      "Iteration =    84 of   500 | Training cost =  -0.06854873 | Monitoring cost =  -0.21252295 | \n",
      "Iteration =    85 of   500 | Training cost =  -0.07273551 | Monitoring cost =  -0.21537205 | \n",
      "Iteration =    86 of   500 | Training cost =  -0.07685548 | Monitoring cost =  -0.21816374 | \n",
      "Iteration =    87 of   500 | Training cost =  -0.08091108 | Monitoring cost =  -0.22089819 | \n",
      "Iteration =    88 of   500 | Training cost =  -0.08490467 | Monitoring cost =  -0.22357570 | \n",
      "Iteration =    89 of   500 | Training cost =  -0.08883847 | Monitoring cost =  -0.22619665 | \n",
      "Iteration =    90 of   500 | Training cost =  -0.09271464 | Monitoring cost =  -0.22876155 | \n",
      "Iteration =    91 of   500 | Training cost =  -0.09653526 | Monitoring cost =  -0.23127098 | \n",
      "Iteration =    92 of   500 | Training cost =  -0.10030230 | Monitoring cost =  -0.23372565 | \n",
      "Iteration =    93 of   500 | Training cost =  -0.10401769 | Monitoring cost =  -0.23612634 | \n",
      "Iteration =    94 of   500 | Training cost =  -0.10768325 | Monitoring cost =  -0.23847390 | \n",
      "Iteration =    95 of   500 | Training cost =  -0.11130078 | Monitoring cost =  -0.24076929 | \n",
      "Iteration =    96 of   500 | Training cost =  -0.11487197 | Monitoring cost =  -0.24301351 | \n",
      "Iteration =    97 of   500 | Training cost =  -0.11839847 | Monitoring cost =  -0.24520766 | \n",
      "Iteration =    98 of   500 | Training cost =  -0.12188188 | Monitoring cost =  -0.24735288 | \n",
      "Iteration =    99 of   500 | Training cost =  -0.12532371 | Monitoring cost =  -0.24945037 | \n",
      "Iteration =   100 of   500 | Training cost =  -0.12872545 | Monitoring cost =  -0.25150139 | \n",
      "Iteration =   101 of   500 | Training cost =  -0.13208850 | Monitoring cost =  -0.25350725 | \n",
      "Iteration =   102 of   500 | Training cost =  -0.13541423 | Monitoring cost =  -0.25546929 | \n",
      "Iteration =   103 of   500 | Training cost =  -0.13870395 | Monitoring cost =  -0.25738890 | \n",
      "Iteration =   104 of   500 | Training cost =  -0.14195892 | Monitoring cost =  -0.25926749 | \n",
      "Iteration =   105 of   500 | Training cost =  -0.14518032 | Monitoring cost =  -0.26110653 | \n",
      "Iteration =   106 of   500 | Training cost =  -0.14836934 | Monitoring cost =  -0.26290749 | \n",
      "Iteration =   107 of   500 | Training cost =  -0.15152706 | Monitoring cost =  -0.26467188 | \n",
      "Iteration =   108 of   500 | Training cost =  -0.15465455 | Monitoring cost =  -0.26640124 | \n",
      "Iteration =   109 of   500 | Training cost =  -0.15775281 | Monitoring cost =  -0.26809710 | \n",
      "Iteration =   110 of   500 | Training cost =  -0.16082282 | Monitoring cost =  -0.26976105 | \n",
      "Iteration =   111 of   500 | Training cost =  -0.16386550 | Monitoring cost =  -0.27139466 | \n",
      "Iteration =   112 of   500 | Training cost =  -0.16688171 | Monitoring cost =  -0.27299953 | \n",
      "Iteration =   113 of   500 | Training cost =  -0.16987231 | Monitoring cost =  -0.27457728 | \n",
      "Iteration =   114 of   500 | Training cost =  -0.17283809 | Monitoring cost =  -0.27612953 | \n",
      "Iteration =   115 of   500 | Training cost =  -0.17577981 | Monitoring cost =  -0.27765792 | \n",
      "Iteration =   116 of   500 | Training cost =  -0.17869819 | Monitoring cost =  -0.27916409 | \n",
      "Iteration =   117 of   500 | Training cost =  -0.18159392 | Monitoring cost =  -0.28064969 | \n",
      "Iteration =   118 of   500 | Training cost =  -0.18446766 | Monitoring cost =  -0.28211638 | \n",
      "Iteration =   119 of   500 | Training cost =  -0.18732004 | Monitoring cost =  -0.28356584 | \n",
      "Iteration =   120 of   500 | Training cost =  -0.19015165 | Monitoring cost =  -0.28499973 | \n",
      "Iteration =   121 of   500 | Training cost =  -0.19296308 | Monitoring cost =  -0.28641974 | \n",
      "Iteration =   122 of   500 | Training cost =  -0.19575485 | Monitoring cost =  -0.28782754 | \n",
      "Iteration =   123 of   500 | Training cost =  -0.19852752 | Monitoring cost =  -0.28922483 | \n",
      "Iteration =   124 of   500 | Training cost =  -0.20128157 | Monitoring cost =  -0.29061329 | \n",
      "Iteration =   125 of   500 | Training cost =  -0.20401751 | Monitoring cost =  -0.29199462 | \n",
      "Iteration =   126 of   500 | Training cost =  -0.20673580 | Monitoring cost =  -0.29337050 | \n",
      "Iteration =   127 of   500 | Training cost =  -0.20943692 | Monitoring cost =  -0.29474263 | \n",
      "Iteration =   128 of   500 | Training cost =  -0.21212130 | Monitoring cost =  -0.29611271 | \n",
      "Iteration =   129 of   500 | Training cost =  -0.21478941 | Monitoring cost =  -0.29748240 | \n",
      "Iteration =   130 of   500 | Training cost =  -0.21744167 | Monitoring cost =  -0.29885341 | \n",
      "Iteration =   131 of   500 | Training cost =  -0.22007851 | Monitoring cost =  -0.30022740 | \n",
      "Iteration =   132 of   500 | Training cost =  -0.22270037 | Monitoring cost =  -0.30160606 | \n",
      "Iteration =   133 of   500 | Training cost =  -0.22530767 | Monitoring cost =  -0.30299104 | \n",
      "Iteration =   134 of   500 | Training cost =  -0.22790086 | Monitoring cost =  -0.30438399 | \n",
      "Iteration =   135 of   500 | Training cost =  -0.23048034 | Monitoring cost =  -0.30578656 | \n",
      "Iteration =   136 of   500 | Training cost =  -0.23304658 | Monitoring cost =  -0.30720037 | \n",
      "Iteration =   137 of   500 | Training cost =  -0.23560000 | Monitoring cost =  -0.30862704 | \n",
      "Iteration =   138 of   500 | Training cost =  -0.23814105 | Monitoring cost =  -0.31006816 | \n",
      "Iteration =   139 of   500 | Training cost =  -0.24067020 | Monitoring cost =  -0.31152531 | \n",
      "Iteration =   140 of   500 | Training cost =  -0.24318791 | Monitoring cost =  -0.31300005 | \n",
      "Iteration =   141 of   500 | Training cost =  -0.24569466 | Monitoring cost =  -0.31449390 | \n",
      "Iteration =   142 of   500 | Training cost =  -0.24819092 | Monitoring cost =  -0.31600838 | \n",
      "Iteration =   143 of   500 | Training cost =  -0.25067720 | Monitoring cost =  -0.31754497 | \n",
      "Iteration =   144 of   500 | Training cost =  -0.25315401 | Monitoring cost =  -0.31910513 | \n",
      "Iteration =   145 of   500 | Training cost =  -0.25562187 | Monitoring cost =  -0.32069027 | \n",
      "Iteration =   146 of   500 | Training cost =  -0.25808131 | Monitoring cost =  -0.32230179 | \n",
      "Iteration =   147 of   500 | Training cost =  -0.26053287 | Monitoring cost =  -0.32394106 | \n",
      "Iteration =   148 of   500 | Training cost =  -0.26297712 | Monitoring cost =  -0.32560938 | \n",
      "Iteration =   149 of   500 | Training cost =  -0.26541462 | Monitoring cost =  -0.32730807 | \n",
      "Iteration =   150 of   500 | Training cost =  -0.26784596 | Monitoring cost =  -0.32903835 | \n",
      "Iteration =   151 of   500 | Training cost =  -0.27027174 | Monitoring cost =  -0.33080145 | \n",
      "Iteration =   152 of   500 | Training cost =  -0.27269255 | Monitoring cost =  -0.33259853 | \n",
      "Iteration =   153 of   500 | Training cost =  -0.27510901 | Monitoring cost =  -0.33443073 | \n",
      "Iteration =   154 of   500 | Training cost =  -0.27752176 | Monitoring cost =  -0.33629912 | \n",
      "Iteration =   155 of   500 | Training cost =  -0.27993142 | Monitoring cost =  -0.33820476 | \n",
      "Iteration =   156 of   500 | Training cost =  -0.28233865 | Monitoring cost =  -0.34014865 | \n",
      "Iteration =   157 of   500 | Training cost =  -0.28474410 | Monitoring cost =  -0.34213173 | \n",
      "Iteration =   158 of   500 | Training cost =  -0.28714843 | Monitoring cost =  -0.34415492 | \n",
      "Iteration =   159 of   500 | Training cost =  -0.28955231 | Monitoring cost =  -0.34621909 | \n",
      "Iteration =   160 of   500 | Training cost =  -0.29195641 | Monitoring cost =  -0.34832505 | \n",
      "Iteration =   161 of   500 | Training cost =  -0.29436141 | Monitoring cost =  -0.35047357 | \n",
      "Iteration =   162 of   500 | Training cost =  -0.29676801 | Monitoring cost =  -0.35266540 | \n",
      "Iteration =   163 of   500 | Training cost =  -0.29917687 | Monitoring cost =  -0.35490120 | \n",
      "Iteration =   164 of   500 | Training cost =  -0.30158871 | Monitoring cost =  -0.35718162 | \n",
      "Iteration =   165 of   500 | Training cost =  -0.30400420 | Monitoring cost =  -0.35950726 | \n",
      "Iteration =   166 of   500 | Training cost =  -0.30642404 | Monitoring cost =  -0.36187866 | \n",
      "Iteration =   167 of   500 | Training cost =  -0.30884893 | Monitoring cost =  -0.36429634 | \n",
      "Iteration =   168 of   500 | Training cost =  -0.31127956 | Monitoring cost =  -0.36676076 | \n",
      "Iteration =   169 of   500 | Training cost =  -0.31371662 | Monitoring cost =  -0.36927236 | \n",
      "Iteration =   170 of   500 | Training cost =  -0.31616082 | Monitoring cost =  -0.37183152 | \n",
      "Iteration =   171 of   500 | Training cost =  -0.31861282 | Monitoring cost =  -0.37443859 | \n",
      "Iteration =   172 of   500 | Training cost =  -0.32107334 | Monitoring cost =  -0.37709389 | \n",
      "Iteration =   173 of   500 | Training cost =  -0.32354305 | Monitoring cost =  -0.37979771 | \n",
      "Iteration =   174 of   500 | Training cost =  -0.32602265 | Monitoring cost =  -0.38255028 | \n",
      "Iteration =   175 of   500 | Training cost =  -0.32851281 | Monitoring cost =  -0.38535183 | \n",
      "Iteration =   176 of   500 | Training cost =  -0.33101422 | Monitoring cost =  -0.38820254 | \n",
      "Iteration =   177 of   500 | Training cost =  -0.33352755 | Monitoring cost =  -0.39110258 | \n",
      "Iteration =   178 of   500 | Training cost =  -0.33605350 | Monitoring cost =  -0.39405208 | \n",
      "Iteration =   179 of   500 | Training cost =  -0.33859273 | Monitoring cost =  -0.39705116 | \n",
      "Iteration =   180 of   500 | Training cost =  -0.34114592 | Monitoring cost =  -0.40009990 | \n",
      "Iteration =   181 of   500 | Training cost =  -0.34371376 | Monitoring cost =  -0.40319838 | \n",
      "Iteration =   182 of   500 | Training cost =  -0.34629693 | Monitoring cost =  -0.40634665 | \n",
      "Iteration =   183 of   500 | Training cost =  -0.34889610 | Monitoring cost =  -0.40954476 | \n",
      "Iteration =   184 of   500 | Training cost =  -0.35151197 | Monitoring cost =  -0.41279273 | \n",
      "Iteration =   185 of   500 | Training cost =  -0.35414523 | Monitoring cost =  -0.41609058 | \n",
      "Iteration =   186 of   500 | Training cost =  -0.35679657 | Monitoring cost =  -0.41943832 | \n",
      "Iteration =   187 of   500 | Training cost =  -0.35946670 | Monitoring cost =  -0.42283595 | \n",
      "Iteration =   188 of   500 | Training cost =  -0.36215634 | Monitoring cost =  -0.42628347 | \n",
      "Iteration =   189 of   500 | Training cost =  -0.36486620 | Monitoring cost =  -0.42978086 | \n",
      "Iteration =   190 of   500 | Training cost =  -0.36759702 | Monitoring cost =  -0.43332813 | \n",
      "Iteration =   191 of   500 | Training cost =  -0.37034955 | Monitoring cost =  -0.43692527 | \n",
      "Iteration =   192 of   500 | Training cost =  -0.37312456 | Monitoring cost =  -0.44057226 | \n",
      "Iteration =   193 of   500 | Training cost =  -0.37592282 | Monitoring cost =  -0.44426911 | \n",
      "Iteration =   194 of   500 | Training cost =  -0.37874513 | Monitoring cost =  -0.44801581 | \n",
      "Iteration =   195 of   500 | Training cost =  -0.38159232 | Monitoring cost =  -0.45181237 | \n",
      "Iteration =   196 of   500 | Training cost =  -0.38446522 | Monitoring cost =  -0.45565879 | \n",
      "Iteration =   197 of   500 | Training cost =  -0.38736469 | Monitoring cost =  -0.45955510 | \n",
      "Iteration =   198 of   500 | Training cost =  -0.39029163 | Monitoring cost =  -0.46350132 | \n",
      "Iteration =   199 of   500 | Training cost =  -0.39324695 | Monitoring cost =  -0.46749748 | \n",
      "Iteration =   200 of   500 | Training cost =  -0.39623159 | Monitoring cost =  -0.47154361 | \n",
      "Iteration =   201 of   500 | Training cost =  -0.39924652 | Monitoring cost =  -0.47563976 | \n",
      "Iteration =   202 of   500 | Training cost =  -0.40229275 | Monitoring cost =  -0.47978598 | \n",
      "Iteration =   203 of   500 | Training cost =  -0.40537132 | Monitoring cost =  -0.48398233 | \n",
      "Iteration =   204 of   500 | Training cost =  -0.40848328 | Monitoring cost =  -0.48822886 | \n",
      "Iteration =   205 of   500 | Training cost =  -0.41162974 | Monitoring cost =  -0.49252565 | \n",
      "Iteration =   206 of   500 | Training cost =  -0.41481184 | Monitoring cost =  -0.49687277 | \n",
      "Iteration =   207 of   500 | Training cost =  -0.41803075 | Monitoring cost =  -0.50127029 | \n",
      "Iteration =   208 of   500 | Training cost =  -0.42128768 | Monitoring cost =  -0.50571828 | \n",
      "Iteration =   209 of   500 | Training cost =  -0.42458386 | Monitoring cost =  -0.51021683 | \n",
      "Iteration =   210 of   500 | Training cost =  -0.42792058 | Monitoring cost =  -0.51476599 | \n",
      "Iteration =   211 of   500 | Training cost =  -0.43129916 | Monitoring cost =  -0.51936585 | \n",
      "Iteration =   212 of   500 | Training cost =  -0.43472094 | Monitoring cost =  -0.52401647 | \n",
      "Iteration =   213 of   500 | Training cost =  -0.43818731 | Monitoring cost =  -0.52871789 | \n",
      "Iteration =   214 of   500 | Training cost =  -0.44169968 | Monitoring cost =  -0.53347017 | \n",
      "Iteration =   215 of   500 | Training cost =  -0.44525952 | Monitoring cost =  -0.53827334 | \n",
      "Iteration =   216 of   500 | Training cost =  -0.44886829 | Monitoring cost =  -0.54312740 | \n",
      "Iteration =   217 of   500 | Training cost =  -0.45252750 | Monitoring cost =  -0.54803236 | \n",
      "Iteration =   218 of   500 | Training cost =  -0.45623870 | Monitoring cost =  -0.55298819 | \n",
      "Iteration =   219 of   500 | Training cost =  -0.46000342 | Monitoring cost =  -0.55799483 | \n",
      "Iteration =   220 of   500 | Training cost =  -0.46382324 | Monitoring cost =  -0.56305221 | \n",
      "Iteration =   221 of   500 | Training cost =  -0.46769975 | Monitoring cost =  -0.56816021 | \n",
      "Iteration =   222 of   500 | Training cost =  -0.47163451 | Monitoring cost =  -0.57331868 | \n",
      "Iteration =   223 of   500 | Training cost =  -0.47562913 | Monitoring cost =  -0.57852742 | \n",
      "Iteration =   224 of   500 | Training cost =  -0.47968516 | Monitoring cost =  -0.58378618 | \n",
      "Iteration =   225 of   500 | Training cost =  -0.48380417 | Monitoring cost =  -0.58909468 | \n",
      "Iteration =   226 of   500 | Training cost =  -0.48798768 | Monitoring cost =  -0.59445255 | \n",
      "Iteration =   227 of   500 | Training cost =  -0.49223716 | Monitoring cost =  -0.59985938 | \n",
      "Iteration =   228 of   500 | Training cost =  -0.49655402 | Monitoring cost =  -0.60531468 | \n",
      "Iteration =   229 of   500 | Training cost =  -0.50093962 | Monitoring cost =  -0.61081787 | \n",
      "Iteration =   230 of   500 | Training cost =  -0.50539519 | Monitoring cost =  -0.61636830 | \n",
      "Iteration =   231 of   500 | Training cost =  -0.50992188 | Monitoring cost =  -0.62196521 | \n",
      "Iteration =   232 of   500 | Training cost =  -0.51452067 | Monitoring cost =  -0.62760774 | \n",
      "Iteration =   233 of   500 | Training cost =  -0.51919238 | Monitoring cost =  -0.63329492 | \n",
      "Iteration =   234 of   500 | Training cost =  -0.52393766 | Monitoring cost =  -0.63902564 | \n",
      "Iteration =   235 of   500 | Training cost =  -0.52875690 | Monitoring cost =  -0.64479866 | \n",
      "Iteration =   236 of   500 | Training cost =  -0.53365027 | Monitoring cost =  -0.65061261 | \n",
      "Iteration =   237 of   500 | Training cost =  -0.53861760 | Monitoring cost =  -0.65646591 | \n",
      "Iteration =   238 of   500 | Training cost =  -0.54365842 | Monitoring cost =  -0.66235684 | \n",
      "Iteration =   239 of   500 | Training cost =  -0.54877189 | Monitoring cost =  -0.66828349 | \n",
      "Iteration =   240 of   500 | Training cost =  -0.55395674 | Monitoring cost =  -0.67424372 | \n",
      "Iteration =   241 of   500 | Training cost =  -0.55921129 | Monitoring cost =  -0.68023519 | \n",
      "Iteration =   242 of   500 | Training cost =  -0.56453335 | Monitoring cost =  -0.68625531 | \n",
      "Iteration =   243 of   500 | Training cost =  -0.56992022 | Monitoring cost =  -0.69230125 | \n",
      "Iteration =   244 of   500 | Training cost =  -0.57536867 | Monitoring cost =  -0.69836993 | \n",
      "Iteration =   245 of   500 | Training cost =  -0.58087490 | Monitoring cost =  -0.70445797 | \n",
      "Iteration =   246 of   500 | Training cost =  -0.58643452 | Monitoring cost =  -0.71056172 | \n",
      "Iteration =   247 of   500 | Training cost =  -0.59204259 | Monitoring cost =  -0.71667724 | \n",
      "Iteration =   248 of   500 | Training cost =  -0.59769357 | Monitoring cost =  -0.72280029 | \n",
      "Iteration =   249 of   500 | Training cost =  -0.60338137 | Monitoring cost =  -0.72892632 | \n",
      "Iteration =   250 of   500 | Training cost =  -0.60909938 | Monitoring cost =  -0.73505050 | \n",
      "Iteration =   251 of   500 | Training cost =  -0.61484050 | Monitoring cost =  -0.74116771 | \n",
      "Iteration =   252 of   500 | Training cost =  -0.62059723 | Monitoring cost =  -0.74727255 | \n",
      "Iteration =   253 of   500 | Training cost =  -0.62636171 | Monitoring cost =  -0.75335937 | \n",
      "Iteration =   254 of   500 | Training cost =  -0.63212580 | Monitoring cost =  -0.75942230 | \n",
      "Iteration =   255 of   500 | Training cost =  -0.63788119 | Monitoring cost =  -0.76545525 | \n",
      "Iteration =   256 of   500 | Training cost =  -0.64361949 | Monitoring cost =  -0.77145200 | \n",
      "Iteration =   257 of   500 | Training cost =  -0.64933232 | Monitoring cost =  -0.77740619 | \n",
      "Iteration =   258 of   500 | Training cost =  -0.65501143 | Monitoring cost =  -0.78331141 | \n",
      "Iteration =   259 of   500 | Training cost =  -0.66064875 | Monitoring cost =  -0.78916124 | \n",
      "Iteration =   260 of   500 | Training cost =  -0.66623653 | Monitoring cost =  -0.79494927 | \n",
      "Iteration =   261 of   500 | Training cost =  -0.67176741 | Monitoring cost =  -0.80066923 | \n",
      "Iteration =   262 of   500 | Training cost =  -0.67723446 | Monitoring cost =  -0.80631498 | \n",
      "Iteration =   263 of   500 | Training cost =  -0.68263127 | Monitoring cost =  -0.81188060 | \n",
      "Iteration =   264 of   500 | Training cost =  -0.68795197 | Monitoring cost =  -0.81736044 | \n",
      "Iteration =   265 of   500 | Training cost =  -0.69319129 | Monitoring cost =  -0.82274916 | \n",
      "Iteration =   266 of   500 | Training cost =  -0.69834454 | Monitoring cost =  -0.82804179 | \n",
      "Iteration =   267 of   500 | Training cost =  -0.70340764 | Monitoring cost =  -0.83323374 | \n",
      "Iteration =   268 of   500 | Training cost =  -0.70837711 | Monitoring cost =  -0.83832087 | \n",
      "Iteration =   269 of   500 | Training cost =  -0.71325005 | Monitoring cost =  -0.84329948 | \n",
      "Iteration =   270 of   500 | Training cost =  -0.71802412 | Monitoring cost =  -0.84816634 | \n",
      "Iteration =   271 of   500 | Training cost =  -0.72269751 | Monitoring cost =  -0.85291872 | \n",
      "Iteration =   272 of   500 | Training cost =  -0.72726889 | Monitoring cost =  -0.85755435 | \n",
      "Iteration =   273 of   500 | Training cost =  -0.73173741 | Monitoring cost =  -0.86207144 | \n",
      "Iteration =   274 of   500 | Training cost =  -0.73610263 | Monitoring cost =  -0.86646867 | \n",
      "Iteration =   275 of   500 | Training cost =  -0.74036447 | Monitoring cost =  -0.87074518 | \n",
      "Iteration =   276 of   500 | Training cost =  -0.74452321 | Monitoring cost =  -0.87490052 | \n",
      "Iteration =   277 of   500 | Training cost =  -0.74857943 | Monitoring cost =  -0.87893466 | \n",
      "Iteration =   278 of   500 | Training cost =  -0.75253397 | Monitoring cost =  -0.88284796 | \n",
      "Iteration =   279 of   500 | Training cost =  -0.75638789 | Monitoring cost =  -0.88664112 | \n",
      "Iteration =   280 of   500 | Training cost =  -0.76014246 | Monitoring cost =  -0.89031517 | \n",
      "Iteration =   281 of   500 | Training cost =  -0.76379912 | Monitoring cost =  -0.89387143 | \n",
      "Iteration =   282 of   500 | Training cost =  -0.76735944 | Monitoring cost =  -0.89731148 | \n",
      "Iteration =   283 of   500 | Training cost =  -0.77082512 | Monitoring cost =  -0.90063715 | \n",
      "Iteration =   284 of   500 | Training cost =  -0.77419796 | Monitoring cost =  -0.90385046 | \n",
      "Iteration =   285 of   500 | Training cost =  -0.77747980 | Monitoring cost =  -0.90695361 | \n",
      "Iteration =   286 of   500 | Training cost =  -0.78067259 | Monitoring cost =  -0.90994894 | \n",
      "Iteration =   287 of   500 | Training cost =  -0.78377827 | Monitoring cost =  -0.91283895 | \n",
      "Iteration =   288 of   500 | Training cost =  -0.78679886 | Monitoring cost =  -0.91562621 | \n",
      "Iteration =   289 of   500 | Training cost =  -0.78973635 | Monitoring cost =  -0.91831337 | \n",
      "Iteration =   290 of   500 | Training cost =  -0.79259278 | Monitoring cost =  -0.92090317 | \n",
      "Iteration =   291 of   500 | Training cost =  -0.79537016 | Monitoring cost =  -0.92339836 | \n",
      "Iteration =   292 of   500 | Training cost =  -0.79807052 | Monitoring cost =  -0.92580174 | \n",
      "Iteration =   293 of   500 | Training cost =  -0.80069583 | Monitoring cost =  -0.92811612 | \n",
      "Iteration =   294 of   500 | Training cost =  -0.80324809 | Monitoring cost =  -0.93034430 | \n",
      "Iteration =   295 of   500 | Training cost =  -0.80572926 | Monitoring cost =  -0.93248907 | \n",
      "Iteration =   296 of   500 | Training cost =  -0.80814125 | Monitoring cost =  -0.93455320 | \n",
      "Iteration =   297 of   500 | Training cost =  -0.81048597 | Monitoring cost =  -0.93653944 | \n",
      "Iteration =   298 of   500 | Training cost =  -0.81276528 | Monitoring cost =  -0.93845047 | \n",
      "Iteration =   299 of   500 | Training cost =  -0.81498101 | Monitoring cost =  -0.94028897 | \n",
      "Iteration =   300 of   500 | Training cost =  -0.81713497 | Monitoring cost =  -0.94205753 | \n",
      "Iteration =   301 of   500 | Training cost =  -0.81922890 | Monitoring cost =  -0.94375870 | \n",
      "Iteration =   302 of   500 | Training cost =  -0.82126454 | Monitoring cost =  -0.94539498 | \n",
      "Iteration =   303 of   500 | Training cost =  -0.82324355 | Monitoring cost =  -0.94696879 | \n",
      "Iteration =   304 of   500 | Training cost =  -0.82516759 | Monitoring cost =  -0.94848249 | \n",
      "Iteration =   305 of   500 | Training cost =  -0.82703826 | Monitoring cost =  -0.94993840 | \n",
      "Iteration =   306 of   500 | Training cost =  -0.82885712 | Monitoring cost =  -0.95133873 | \n",
      "Iteration =   307 of   500 | Training cost =  -0.83062571 | Monitoring cost =  -0.95268565 | \n",
      "Iteration =   308 of   500 | Training cost =  -0.83234552 | Monitoring cost =  -0.95398126 | \n",
      "Iteration =   309 of   500 | Training cost =  -0.83401798 | Monitoring cost =  -0.95522759 | \n",
      "Iteration =   310 of   500 | Training cost =  -0.83564453 | Monitoring cost =  -0.95642660 | \n",
      "Iteration =   311 of   500 | Training cost =  -0.83722653 | Monitoring cost =  -0.95758017 | \n",
      "Iteration =   312 of   500 | Training cost =  -0.83876533 | Monitoring cost =  -0.95869014 | \n",
      "Iteration =   313 of   500 | Training cost =  -0.84026222 | Monitoring cost =  -0.95975827 | \n",
      "Iteration =   314 of   500 | Training cost =  -0.84171848 | Monitoring cost =  -0.96078624 | \n",
      "Iteration =   315 of   500 | Training cost =  -0.84313533 | Monitoring cost =  -0.96177571 | \n",
      "Iteration =   316 of   500 | Training cost =  -0.84451398 | Monitoring cost =  -0.96272824 | \n",
      "Iteration =   317 of   500 | Training cost =  -0.84585560 | Monitoring cost =  -0.96364533 | \n",
      "Iteration =   318 of   500 | Training cost =  -0.84716130 | Monitoring cost =  -0.96452846 | \n",
      "Iteration =   319 of   500 | Training cost =  -0.84843219 | Monitoring cost =  -0.96537900 | \n",
      "Iteration =   320 of   500 | Training cost =  -0.84966935 | Monitoring cost =  -0.96619832 | \n",
      "Iteration =   321 of   500 | Training cost =  -0.85087379 | Monitoring cost =  -0.96698768 | \n",
      "Iteration =   322 of   500 | Training cost =  -0.85204653 | Monitoring cost =  -0.96774834 | \n",
      "Iteration =   323 of   500 | Training cost =  -0.85318854 | Monitoring cost =  -0.96848147 | \n",
      "Iteration =   324 of   500 | Training cost =  -0.85430078 | Monitoring cost =  -0.96918822 | \n",
      "Iteration =   325 of   500 | Training cost =  -0.85538414 | Monitoring cost =  -0.96986968 | \n",
      "Iteration =   326 of   500 | Training cost =  -0.85643953 | Monitoring cost =  -0.97052688 | \n",
      "Iteration =   327 of   500 | Training cost =  -0.85746781 | Monitoring cost =  -0.97116085 | \n",
      "Iteration =   328 of   500 | Training cost =  -0.85846982 | Monitoring cost =  -0.97177252 | \n",
      "Iteration =   329 of   500 | Training cost =  -0.85944635 | Monitoring cost =  -0.97236284 | \n",
      "Iteration =   330 of   500 | Training cost =  -0.86039820 | Monitoring cost =  -0.97293267 | \n",
      "Iteration =   331 of   500 | Training cost =  -0.86132612 | Monitoring cost =  -0.97348286 | \n",
      "Iteration =   332 of   500 | Training cost =  -0.86223086 | Monitoring cost =  -0.97401422 | \n",
      "Iteration =   333 of   500 | Training cost =  -0.86311312 | Monitoring cost =  -0.97452753 | \n",
      "Iteration =   334 of   500 | Training cost =  -0.86397360 | Monitoring cost =  -0.97502351 | \n",
      "Iteration =   335 of   500 | Training cost =  -0.86481295 | Monitoring cost =  -0.97550289 | \n",
      "Iteration =   336 of   500 | Training cost =  -0.86563184 | Monitoring cost =  -0.97596634 | \n",
      "Iteration =   337 of   500 | Training cost =  -0.86643087 | Monitoring cost =  -0.97641451 | \n",
      "Iteration =   338 of   500 | Training cost =  -0.86721066 | Monitoring cost =  -0.97684803 | \n",
      "Iteration =   339 of   500 | Training cost =  -0.86797180 | Monitoring cost =  -0.97726747 | \n",
      "Iteration =   340 of   500 | Training cost =  -0.86871484 | Monitoring cost =  -0.97767342 | \n",
      "Iteration =   341 of   500 | Training cost =  -0.86944034 | Monitoring cost =  -0.97806642 | \n",
      "Iteration =   342 of   500 | Training cost =  -0.87014882 | Monitoring cost =  -0.97844698 | \n",
      "Iteration =   343 of   500 | Training cost =  -0.87084081 | Monitoring cost =  -0.97881561 | \n",
      "Iteration =   344 of   500 | Training cost =  -0.87151678 | Monitoring cost =  -0.97917279 | \n",
      "Iteration =   345 of   500 | Training cost =  -0.87217722 | Monitoring cost =  -0.97951895 | \n",
      "Iteration =   346 of   500 | Training cost =  -0.87282260 | Monitoring cost =  -0.97985456 | \n",
      "Iteration =   347 of   500 | Training cost =  -0.87345336 | Monitoring cost =  -0.98018001 | \n",
      "Iteration =   348 of   500 | Training cost =  -0.87406993 | Monitoring cost =  -0.98049570 | \n",
      "Iteration =   349 of   500 | Training cost =  -0.87467273 | Monitoring cost =  -0.98080203 | \n",
      "Iteration =   350 of   500 | Training cost =  -0.87526217 | Monitoring cost =  -0.98109935 | \n",
      "Iteration =   351 of   500 | Training cost =  -0.87583864 | Monitoring cost =  -0.98138802 | \n",
      "Iteration =   352 of   500 | Training cost =  -0.87640251 | Monitoring cost =  -0.98166836 | \n",
      "Iteration =   353 of   500 | Training cost =  -0.87695415 | Monitoring cost =  -0.98194070 | \n",
      "Iteration =   354 of   500 | Training cost =  -0.87749391 | Monitoring cost =  -0.98220534 | \n",
      "Iteration =   355 of   500 | Training cost =  -0.87802214 | Monitoring cost =  -0.98246258 | \n",
      "Iteration =   356 of   500 | Training cost =  -0.87853915 | Monitoring cost =  -0.98271269 | \n",
      "Iteration =   357 of   500 | Training cost =  -0.87904528 | Monitoring cost =  -0.98295594 | \n",
      "Iteration =   358 of   500 | Training cost =  -0.87954083 | Monitoring cost =  -0.98319259 | \n",
      "Iteration =   359 of   500 | Training cost =  -0.88002610 | Monitoring cost =  -0.98342289 | \n",
      "Iteration =   360 of   500 | Training cost =  -0.88050137 | Monitoring cost =  -0.98364706 | \n",
      "Iteration =   361 of   500 | Training cost =  -0.88096692 | Monitoring cost =  -0.98386534 | \n",
      "Iteration =   362 of   500 | Training cost =  -0.88142303 | Monitoring cost =  -0.98407794 | \n",
      "Iteration =   363 of   500 | Training cost =  -0.88186995 | Monitoring cost =  -0.98428507 | \n",
      "Iteration =   364 of   500 | Training cost =  -0.88230794 | Monitoring cost =  -0.98448692 | \n",
      "Iteration =   365 of   500 | Training cost =  -0.88273723 | Monitoring cost =  -0.98468368 | \n",
      "Iteration =   366 of   500 | Training cost =  -0.88315807 | Monitoring cost =  -0.98487553 | \n",
      "Iteration =   367 of   500 | Training cost =  -0.88357068 | Monitoring cost =  -0.98506265 | \n",
      "Iteration =   368 of   500 | Training cost =  -0.88397528 | Monitoring cost =  -0.98524520 | \n",
      "Iteration =   369 of   500 | Training cost =  -0.88437208 | Monitoring cost =  -0.98542335 | \n",
      "Iteration =   370 of   500 | Training cost =  -0.88476129 | Monitoring cost =  -0.98559724 | \n",
      "Iteration =   371 of   500 | Training cost =  -0.88514312 | Monitoring cost =  -0.98576703 | \n",
      "Iteration =   372 of   500 | Training cost =  -0.88551775 | Monitoring cost =  -0.98593285 | \n",
      "Iteration =   373 of   500 | Training cost =  -0.88588537 | Monitoring cost =  -0.98609483 | \n",
      "Iteration =   374 of   500 | Training cost =  -0.88624616 | Monitoring cost =  -0.98625311 | \n",
      "Iteration =   375 of   500 | Training cost =  -0.88660029 | Monitoring cost =  -0.98640781 | \n",
      "Iteration =   376 of   500 | Training cost =  -0.88694794 | Monitoring cost =  -0.98655905 | \n",
      "Iteration =   377 of   500 | Training cost =  -0.88728927 | Monitoring cost =  -0.98670694 | \n",
      "Iteration =   378 of   500 | Training cost =  -0.88762444 | Monitoring cost =  -0.98685160 | \n",
      "Iteration =   379 of   500 | Training cost =  -0.88795360 | Monitoring cost =  -0.98699312 | \n",
      "Iteration =   380 of   500 | Training cost =  -0.88827691 | Monitoring cost =  -0.98713161 | \n",
      "Iteration =   381 of   500 | Training cost =  -0.88859450 | Monitoring cost =  -0.98726716 | \n",
      "Iteration =   382 of   500 | Training cost =  -0.88890651 | Monitoring cost =  -0.98739987 | \n",
      "Iteration =   383 of   500 | Training cost =  -0.88921309 | Monitoring cost =  -0.98752983 | \n",
      "Iteration =   384 of   500 | Training cost =  -0.88951436 | Monitoring cost =  -0.98765713 | \n",
      "Iteration =   385 of   500 | Training cost =  -0.88981046 | Monitoring cost =  -0.98778183 | \n",
      "Iteration =   386 of   500 | Training cost =  -0.89010149 | Monitoring cost =  -0.98790404 | \n",
      "Iteration =   387 of   500 | Training cost =  -0.89038760 | Monitoring cost =  -0.98802381 | \n",
      "Iteration =   388 of   500 | Training cost =  -0.89066888 | Monitoring cost =  -0.98814123 | \n",
      "Iteration =   389 of   500 | Training cost =  -0.89094546 | Monitoring cost =  -0.98825636 | \n",
      "Iteration =   390 of   500 | Training cost =  -0.89121744 | Monitoring cost =  -0.98836927 | \n",
      "Iteration =   391 of   500 | Training cost =  -0.89148493 | Monitoring cost =  -0.98848003 | \n",
      "Iteration =   392 of   500 | Training cost =  -0.89174804 | Monitoring cost =  -0.98858871 | \n",
      "Iteration =   393 of   500 | Training cost =  -0.89200686 | Monitoring cost =  -0.98869535 | \n",
      "Iteration =   394 of   500 | Training cost =  -0.89226148 | Monitoring cost =  -0.98880002 | \n",
      "Iteration =   395 of   500 | Training cost =  -0.89251202 | Monitoring cost =  -0.98890278 | \n",
      "Iteration =   396 of   500 | Training cost =  -0.89275855 | Monitoring cost =  -0.98900367 | \n",
      "Iteration =   397 of   500 | Training cost =  -0.89300116 | Monitoring cost =  -0.98910276 | \n",
      "Iteration =   398 of   500 | Training cost =  -0.89323995 | Monitoring cost =  -0.98920008 | \n",
      "Iteration =   399 of   500 | Training cost =  -0.89347499 | Monitoring cost =  -0.98929570 | \n",
      "Iteration =   400 of   500 | Training cost =  -0.89370637 | Monitoring cost =  -0.98938965 | \n",
      "Iteration =   401 of   500 | Training cost =  -0.89393417 | Monitoring cost =  -0.98948198 | \n",
      "Iteration =   402 of   500 | Training cost =  -0.89415846 | Monitoring cost =  -0.98957273 | \n",
      "Iteration =   403 of   500 | Training cost =  -0.89437932 | Monitoring cost =  -0.98966195 | \n",
      "Iteration =   404 of   500 | Training cost =  -0.89459682 | Monitoring cost =  -0.98974968 | \n",
      "Iteration =   405 of   500 | Training cost =  -0.89481103 | Monitoring cost =  -0.98983595 | \n",
      "Iteration =   406 of   500 | Training cost =  -0.89502203 | Monitoring cost =  -0.98992080 | \n",
      "Iteration =   407 of   500 | Training cost =  -0.89522987 | Monitoring cost =  -0.99000427 | \n",
      "Iteration =   408 of   500 | Training cost =  -0.89543464 | Monitoring cost =  -0.99008639 | \n",
      "Iteration =   409 of   500 | Training cost =  -0.89563637 | Monitoring cost =  -0.99016721 | \n",
      "Iteration =   410 of   500 | Training cost =  -0.89583515 | Monitoring cost =  -0.99024674 | \n",
      "Iteration =   411 of   500 | Training cost =  -0.89603103 | Monitoring cost =  -0.99032502 | \n",
      "Iteration =   412 of   500 | Training cost =  -0.89622407 | Monitoring cost =  -0.99040208 | \n",
      "Iteration =   413 of   500 | Training cost =  -0.89641433 | Monitoring cost =  -0.99047795 | \n",
      "Iteration =   414 of   500 | Training cost =  -0.89660185 | Monitoring cost =  -0.99055267 | \n",
      "Iteration =   415 of   500 | Training cost =  -0.89678671 | Monitoring cost =  -0.99062625 | \n",
      "Iteration =   416 of   500 | Training cost =  -0.89696894 | Monitoring cost =  -0.99069872 | \n",
      "Iteration =   417 of   500 | Training cost =  -0.89714861 | Monitoring cost =  -0.99077012 | \n",
      "Iteration =   418 of   500 | Training cost =  -0.89732575 | Monitoring cost =  -0.99084046 | \n",
      "Iteration =   419 of   500 | Training cost =  -0.89750042 | Monitoring cost =  -0.99090977 | \n",
      "Iteration =   420 of   500 | Training cost =  -0.89767268 | Monitoring cost =  -0.99097807 | \n",
      "Iteration =   421 of   500 | Training cost =  -0.89784255 | Monitoring cost =  -0.99104539 | \n",
      "Iteration =   422 of   500 | Training cost =  -0.89801010 | Monitoring cost =  -0.99111174 | \n",
      "Iteration =   423 of   500 | Training cost =  -0.89817536 | Monitoring cost =  -0.99117715 | \n",
      "Iteration =   424 of   500 | Training cost =  -0.89833837 | Monitoring cost =  -0.99124165 | \n",
      "Iteration =   425 of   500 | Training cost =  -0.89849919 | Monitoring cost =  -0.99130524 | \n",
      "Iteration =   426 of   500 | Training cost =  -0.89865785 | Monitoring cost =  -0.99136795 | \n",
      "Iteration =   427 of   500 | Training cost =  -0.89881438 | Monitoring cost =  -0.99142980 | \n",
      "Iteration =   428 of   500 | Training cost =  -0.89896884 | Monitoring cost =  -0.99149080 | \n",
      "Iteration =   429 of   500 | Training cost =  -0.89912125 | Monitoring cost =  -0.99155098 | \n",
      "Iteration =   430 of   500 | Training cost =  -0.89927166 | Monitoring cost =  -0.99161035 | \n",
      "Iteration =   431 of   500 | Training cost =  -0.89942010 | Monitoring cost =  -0.99166893 | \n",
      "Iteration =   432 of   500 | Training cost =  -0.89956661 | Monitoring cost =  -0.99172673 | \n",
      "Iteration =   433 of   500 | Training cost =  -0.89971122 | Monitoring cost =  -0.99178378 | \n",
      "Iteration =   434 of   500 | Training cost =  -0.89985396 | Monitoring cost =  -0.99184007 | \n",
      "Iteration =   435 of   500 | Training cost =  -0.89999488 | Monitoring cost =  -0.99189564 | \n",
      "Iteration =   436 of   500 | Training cost =  -0.90013399 | Monitoring cost =  -0.99195049 | \n",
      "Iteration =   437 of   500 | Training cost =  -0.90027134 | Monitoring cost =  -0.99200464 | \n",
      "Iteration =   438 of   500 | Training cost =  -0.90040695 | Monitoring cost =  -0.99205811 | \n",
      "Iteration =   439 of   500 | Training cost =  -0.90054086 | Monitoring cost =  -0.99211090 | \n",
      "Iteration =   440 of   500 | Training cost =  -0.90067309 | Monitoring cost =  -0.99216303 | \n",
      "Iteration =   441 of   500 | Training cost =  -0.90080368 | Monitoring cost =  -0.99221451 | \n",
      "Iteration =   442 of   500 | Training cost =  -0.90093264 | Monitoring cost =  -0.99226535 | \n",
      "Iteration =   443 of   500 | Training cost =  -0.90106001 | Monitoring cost =  -0.99231557 | \n",
      "Iteration =   444 of   500 | Training cost =  -0.90118583 | Monitoring cost =  -0.99236518 | \n",
      "Iteration =   445 of   500 | Training cost =  -0.90131010 | Monitoring cost =  -0.99241418 | \n",
      "Iteration =   446 of   500 | Training cost =  -0.90143286 | Monitoring cost =  -0.99246260 | \n",
      "Iteration =   447 of   500 | Training cost =  -0.90155413 | Monitoring cost =  -0.99251043 | \n",
      "Iteration =   448 of   500 | Training cost =  -0.90167395 | Monitoring cost =  -0.99255770 | \n",
      "Iteration =   449 of   500 | Training cost =  -0.90179232 | Monitoring cost =  -0.99260441 | \n",
      "Iteration =   450 of   500 | Training cost =  -0.90190928 | Monitoring cost =  -0.99265056 | \n",
      "Iteration =   451 of   500 | Training cost =  -0.90202486 | Monitoring cost =  -0.99269618 | \n",
      "Iteration =   452 of   500 | Training cost =  -0.90213906 | Monitoring cost =  -0.99274127 | \n",
      "Iteration =   453 of   500 | Training cost =  -0.90225192 | Monitoring cost =  -0.99278584 | \n",
      "Iteration =   454 of   500 | Training cost =  -0.90236345 | Monitoring cost =  -0.99282990 | \n",
      "Iteration =   455 of   500 | Training cost =  -0.90247369 | Monitoring cost =  -0.99287346 | \n",
      "Iteration =   456 of   500 | Training cost =  -0.90258264 | Monitoring cost =  -0.99291652 | \n",
      "Iteration =   457 of   500 | Training cost =  -0.90269033 | Monitoring cost =  -0.99295909 | \n",
      "Iteration =   458 of   500 | Training cost =  -0.90279678 | Monitoring cost =  -0.99300119 | \n",
      "Iteration =   459 of   500 | Training cost =  -0.90290201 | Monitoring cost =  -0.99304282 | \n",
      "Iteration =   460 of   500 | Training cost =  -0.90300604 | Monitoring cost =  -0.99308398 | \n",
      "Iteration =   461 of   500 | Training cost =  -0.90310889 | Monitoring cost =  -0.99312469 | \n",
      "Iteration =   462 of   500 | Training cost =  -0.90321057 | Monitoring cost =  -0.99316496 | \n",
      "Iteration =   463 of   500 | Training cost =  -0.90331111 | Monitoring cost =  -0.99320478 | \n",
      "Iteration =   464 of   500 | Training cost =  -0.90341051 | Monitoring cost =  -0.99324418 | \n",
      "Iteration =   465 of   500 | Training cost =  -0.90350881 | Monitoring cost =  -0.99328314 | \n",
      "Iteration =   466 of   500 | Training cost =  -0.90360601 | Monitoring cost =  -0.99332169 | \n",
      "Iteration =   467 of   500 | Training cost =  -0.90370214 | Monitoring cost =  -0.99335983 | \n",
      "Iteration =   468 of   500 | Training cost =  -0.90379721 | Monitoring cost =  -0.99339756 | \n",
      "Iteration =   469 of   500 | Training cost =  -0.90389123 | Monitoring cost =  -0.99343489 | \n",
      "Iteration =   470 of   500 | Training cost =  -0.90398422 | Monitoring cost =  -0.99347183 | \n",
      "Iteration =   471 of   500 | Training cost =  -0.90407620 | Monitoring cost =  -0.99350838 | \n",
      "Iteration =   472 of   500 | Training cost =  -0.90416718 | Monitoring cost =  -0.99354455 | \n",
      "Iteration =   473 of   500 | Training cost =  -0.90425718 | Monitoring cost =  -0.99358034 | \n",
      "Iteration =   474 of   500 | Training cost =  -0.90434621 | Monitoring cost =  -0.99361577 | \n",
      "Iteration =   475 of   500 | Training cost =  -0.90443428 | Monitoring cost =  -0.99365083 | \n",
      "Iteration =   476 of   500 | Training cost =  -0.90452142 | Monitoring cost =  -0.99368553 | \n",
      "Iteration =   477 of   500 | Training cost =  -0.90460763 | Monitoring cost =  -0.99371988 | \n",
      "Iteration =   478 of   500 | Training cost =  -0.90469292 | Monitoring cost =  -0.99375388 | \n",
      "Iteration =   479 of   500 | Training cost =  -0.90477732 | Monitoring cost =  -0.99378754 | \n",
      "Iteration =   480 of   500 | Training cost =  -0.90486083 | Monitoring cost =  -0.99382086 | \n",
      "Iteration =   481 of   500 | Training cost =  -0.90494347 | Monitoring cost =  -0.99385384 | \n",
      "Iteration =   482 of   500 | Training cost =  -0.90502524 | Monitoring cost =  -0.99388650 | \n",
      "Iteration =   483 of   500 | Training cost =  -0.90510617 | Monitoring cost =  -0.99391884 | \n",
      "Iteration =   484 of   500 | Training cost =  -0.90518626 | Monitoring cost =  -0.99395085 | \n",
      "Iteration =   485 of   500 | Training cost =  -0.90526553 | Monitoring cost =  -0.99398255 | \n",
      "Iteration =   486 of   500 | Training cost =  -0.90534398 | Monitoring cost =  -0.99401394 | \n",
      "Iteration =   487 of   500 | Training cost =  -0.90542163 | Monitoring cost =  -0.99404503 | \n",
      "Iteration =   488 of   500 | Training cost =  -0.90549849 | Monitoring cost =  -0.99407581 | \n",
      "Iteration =   489 of   500 | Training cost =  -0.90557458 | Monitoring cost =  -0.99410630 | \n",
      "Iteration =   490 of   500 | Training cost =  -0.90564989 | Monitoring cost =  -0.99413650 | \n",
      "Iteration =   491 of   500 | Training cost =  -0.90572445 | Monitoring cost =  -0.99416640 | \n",
      "Iteration =   492 of   500 | Training cost =  -0.90579826 | Monitoring cost =  -0.99419602 | \n",
      "Iteration =   493 of   500 | Training cost =  -0.90587133 | Monitoring cost =  -0.99422536 | \n",
      "Iteration =   494 of   500 | Training cost =  -0.90594368 | Monitoring cost =  -0.99425442 | \n",
      "Iteration =   495 of   500 | Training cost =  -0.90601531 | Monitoring cost =  -0.99428321 | \n",
      "Iteration =   496 of   500 | Training cost =  -0.90608623 | Monitoring cost =  -0.99431173 | \n",
      "Iteration =   497 of   500 | Training cost =  -0.90615646 | Monitoring cost =  -0.99433998 | \n",
      "Iteration =   498 of   500 | Training cost =  -0.90622600 | Monitoring cost =  -0.99436796 | \n",
      "Iteration =   499 of   500 | Training cost =  -0.90629486 | Monitoring cost =  -0.99439569 | \n",
      "Iteration =   500 of   500 | Training cost =  -0.90636305 | Monitoring cost =  -0.99442317 | \n"
     ]
    }
   ],
   "source": [
    "print(f\"Iteration = {0:5d} of {max_iter:5d} | \" +\n",
    "       \"Training cost = {:12.8f} | \".format(costs_lists['training'][-1]) +\n",
    "       \"Monitoring cost = {:12.8f} | \".format(costs_lists['monitoring'][-1]))\n",
    "for it in range(max_iter):\n",
    "    weights = opt.step(training_cost, weights)\n",
    "    costs_lists['training'].append(training_cost(weights))\n",
    "    costs_lists['monitoring'].append(monitoring_cost(weights))\n",
    "    if (it + 1) % 1 == 0:\n",
    "        print(f\"Iteration = {it+1:5d} of {max_iter:5d} | \" +\n",
    "               \"Training cost = {:12.8f} | \".format(costs_lists['training'][-1]) +\n",
    "               \"Monitoring cost = {:12.8f} | \".format(costs_lists['monitoring'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs_lists['training'])\n",
    "plt.plot(costs_lists['monitoring'])\n",
    "plt.legend(['training', 'monitoring'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our example of target Hamiltonian is a single Pauli string, we know \n",
    "without needing any training that it has only $\\pm 1$ eigenvalues. \n",
    "It is a very simple example. but we see that the training of our circuit using\n",
    "the gadget Hamiltonian as cost function did indeed allow to reach the \n",
    "global minimum of the target cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References  \n",
    "[1] our paper on arxiv  \n",
    "[2] Cerezo, M., Sone, A., Volkoff, T. et al. Cost function dependent barren plateaus in shallow parametrized quantum circuits. Nat Commun 12, 1791 (2021). https://doi.org/10.1038/s41467-021-21728-w  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf6ca161eb71b8721933a48be547b7c04ae77679351d445b45174f66d40cf8c4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('thesis-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
